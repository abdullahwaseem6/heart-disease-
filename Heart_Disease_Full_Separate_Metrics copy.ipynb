{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57be4d38",
   "metadata": {},
   "source": [
    "# ‚ù§Ô∏è Full ML Evaluation per Model\n",
    "\n",
    "This notebook trains 10 ML models on the Heart Disease dataset and shows the following **SEPARATELY for EACH model**:\n",
    "\n",
    "1. ‚úÖ Classification Report (text)\n",
    "2. ‚úÖ Confusion Matrix (plot)\n",
    "3. ‚úÖ Accuracy (bar plot)\n",
    "4. ‚úÖ Loss Value & Loss Plot (if applicable)\n",
    "5. ‚úÖ AUC Score (text)\n",
    "6. ‚úÖ ROC Curve (plot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06321003",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26316b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score, roc_auc_score,\n",
    "    roc_curve, log_loss\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "# import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f00b351",
   "metadata": {},
   "source": [
    "## üìÇ Step 2: Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04532501",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"heart.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218a5819",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Step 3: Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0189134e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df.drop('output', axis=1)\n",
    "y = df['output']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be9816b",
   "metadata": {},
   "source": [
    "## ü§ñ Step 4: Define ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669f0dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"SVM\": SVC(probability=True),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"XGBoost\": xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "    # \"LightGBM\": lgb.LGBMClassifier()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e619258",
   "metadata": {},
   "source": [
    "## üìä Step 5: Train & Evaluate Each Model Separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c5b0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n================ {name} ================\\n\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    loss = log_loss(y_test, y_prob)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cr = classification_report(y_test, y_pred)\n",
    "\n",
    "    print(\"üìã Classification Report:\")\n",
    "    print(cr)\n",
    "\n",
    "    print(f\"‚úÖ Accuracy: {acc:.4f}\")\n",
    "    print(f\"‚úÖ AUC Score: {auc:.4f}\")\n",
    "    print(f\"‚úÖ Log Loss: {loss:.4f}\")\n",
    "\n",
    "    # 1. Confusion Matrix Plot\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title(f\"Confusion Matrix - {name}\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.show()\n",
    "\n",
    "    # 2. Accuracy Bar\n",
    "    plt.figure(figsize=(3, 2))\n",
    "    plt.bar([\"Accuracy\"], [acc], color='green')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title(f\"Accuracy - {name}\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.show()\n",
    "\n",
    "    # 3. Loss Bar\n",
    "    plt.figure(figsize=(3, 2))\n",
    "    plt.bar([\"Log Loss\"], [loss], color='red')\n",
    "    plt.title(f\"Log Loss - {name}\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "\n",
    "    # 4. ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    plt.plot(fpr, tpr, label=f\"AUC = {auc:.2f}\")\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(f\"ROC Curve - {name}\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d259b3",
   "metadata": {},
   "source": [
    "## üìà Step 6: Summary Comparison of All Models (Accuracy, AUC, Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440f3079",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Collect all model results\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    loss = log_loss(y_test, y_prob)\n",
    "    results[name] = {\"accuracy\": acc, \"auc\": auc, \"loss\": loss}\n",
    "\n",
    "# Bar plots\n",
    "names = list(results.keys())\n",
    "accuracies = [results[n]['accuracy'] for n in names]\n",
    "aucs = [results[n]['auc'] for n in names]\n",
    "losses = [results[n]['loss'] for n in names]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(x=names, y=accuracies)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Model Accuracy Comparison\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(x=names, y=aucs)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Model AUC Score Comparison\")\n",
    "plt.ylabel(\"AUC Score\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(x=names, y=losses)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Model Log Loss Comparison\")\n",
    "plt.ylabel(\"Log Loss\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
